{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 4**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/scpd-proed/XCS224W-Colab4/blob/main/Notebook/XCS224W_Colab4.ipynb)\n",
        "\n",
        "Before opening the colab with the badge, you would need to allow Google Colab to access the GitHub private repositories. Please check therefore [this tutorial](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb#:~:text=Navigate%20to%20http%3A%2F%2Fcolab,to%20read%20the%20private%20files.).\n",
        "\n",
        "If colab is opened with this badge, make sure please **save copy to drive** in 'File' menu before running the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab, we shift our focus from homogenous graphs to heterogeneous graphs. Heterogeneous graphs extend the traditional homogenous graphs that we have been working with by incorporating different node and edge types. This additional information allows us to extend the graph neural nework models that we have worked with before. Namely, we can apply heterogenous message passing, where different message types now exist between different node and edge type relationships. \n",
        "\n",
        "In this notebook, you will first learn how to transform NetworkX graphs into DeepSNAP representations. Then, you will dive deeper into how DeepSNAP stores and represents heterogeneous graphs as PyTorch Tensors.\n",
        "\n",
        "With this knowledge, you will build your own heterogenous graph neural netowrk models using PyTorch Geometric and DeepSNAP. You will then apply your models for a node property prediction task; specifically, you will evaluate these models on the heterogeneous ACM node prediction dataset.\n",
        "\n",
        "Lastly, we give a sneak preview into the work you will do on Colab5. To close out this assignment we introduce the concept of Neighborhood Sampling and mini-batch training for scaling GNNs to large graphs.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells in each section**, so that the intermediate variables / packages will carry over to the next cell\n",
        "\n",
        "Have fun and good luck on Colab 4 :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "## Setup\n",
        "First let us check which version of PyTorch you are running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkP8pA1qBE5",
        "outputId": "9c94c3b0-5f14-4c22-d394-e7a154478396"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nor9gj5c6wz"
      },
      "source": [
        "Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "d3f20ea0-5188-4bd5-bfcd-f1ee02a78795"
      },
      "outputs": [],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
        "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
        "  !pip install torch-geometric\n",
        "  # Fix for Deepsnap PyG 2.4.x compatibility issue (https://github.com/snap-stanford/deepsnap/issues/53)\n",
        "  !pip install -q git+https://github.com/SebastianHurubaru/deepsnap.git\n",
        "  !pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpr0ThDgZmZV",
        "outputId": "b6943313-b0c4-42d8-db36-ef582589ed61"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !nvcc --version\n",
        "  !python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "1cc0fd09-4c75-4a1a-d4cc-60f7a1bdaca7"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  import torch\n",
        "  import torch_geometric\n",
        "  print(torch.__version__)\n",
        "  print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXlf4MtYrbz"
      },
      "source": [
        "# 1) DeepSNAP Heterogeneous Graph\n",
        "\n",
        "First, you will explore how to transform a NetworkX graph into the format supported by DeepSNAP. \n",
        "\n",
        "DeepSNAP extends its traditional graph representation to include heterogeneous graphs by including the following graph property features:  \n",
        "* `node_feature`: The feature of each node (`torch.tensor`)\n",
        "* `edge_feature`: The feature of each edge (`torch.tensor`)\n",
        "* `node_label`: The label of each node (`int`)\n",
        "* `node_type`: The type of each node (`string`)\n",
        "* `edge_type`: The type of each edge (`string`)\n",
        "\n",
        "where the key **new** features added are `node_type` and `edge_type`, which enables us to perform heterogenous message passing.\n",
        "\n",
        "For this first question you will work with the familiar [karate club graph](https://networkx.github.io/documentation/stable/auto_examples/graph/plot_karate_club.html) seen in Colab 1. To start, since each node in the graph belongs to one of two clubs (club \"Mr. Hi\" or club \"Officer\"), you will treat the club as the `node_type`. The code below demonstrates how to differentiate the nodes in the NetworkX graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "8LQ_z5gcBVA1",
        "outputId": "698afa55-e6fb-4534-c87d-816d1eda0e23"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  from pylab import show\n",
        "  G = nx.karate_club_graph()\n",
        "  community_map = {}\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1][\"club\"] == \"Mr. Hi\":\n",
        "      community_map[node[0]] = 0\n",
        "    else:\n",
        "      community_map[node[0]] = 1\n",
        "  node_color = []\n",
        "  color_map = {0: 0, 1: 1}\n",
        "  node_color = [color_map[community_map[node]] for node in G.nodes()]\n",
        "  pos = nx.spring_layout(G)\n",
        "  plt.figure(figsize=(7, 7))\n",
        "  nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=node_color)\n",
        "  show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JpFb9fTw1lg"
      },
      "source": [
        "### Question 1.1: Assigning Node Type and Node Features (10 points)\n",
        "\n",
        "Using the `community_map` dictionary and graph `G` from above, add node attributes `node_type` and `node_label` to the graph G. Namely, for `node_type` assign nodes in the \"Mr. Hi\" club to a node type `n0` and nodes in club \"Officer\" a node type `n1`. Note: the node type should be a `string` property.\n",
        "\n",
        "Then for `node_label`, assign nodes in \"Mr. Hi\" club to a `node_label` `0` and nodes in club \"Officer\" a `node_label` of `1`.\n",
        "\n",
        "Lastly, assign every node the *tensor* feature vector $[1, 1, 1, 1, 1]$. \n",
        "\n",
        "**Hint**: Look at the NetworkX function `nx.classes.function.set_node_attributes`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zev_hMJHJXK1",
        "outputId": "2cb4f4fe-277d-4a30-b8b1-603492326b29"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def assign_node_types(G, community_map):\n",
        "  # TODO: Implement a function that takes in a NetworkX graph\n",
        "  # G and community map assignment (mapping node id --> 0/1 label)\n",
        "  # and adds 'node_type' as a node_attribute in G.\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note\n",
        "  ## 1. Look up NetworkX `nx.classes.function.set_node_attributes`\n",
        "  ## 2. Look above for the two node type values!\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "def assign_node_labels(G, community_map):\n",
        "  # TODO: Implement a function that takes in a NetworkX graph\n",
        "  # G and community map assignment (mapping node id --> 0/1 label)\n",
        "  # and adds 'node_label' as a node_attribute in G.\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note\n",
        "  ## 1. Look up NetworkX `nx.classes.function.set_node_attributes`\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "def assign_node_features(G):\n",
        "  # TODO: Implement a function that takes in a NetworkX graph\n",
        "  # G and adds 'node_feature' as a node_attribute in G. Each node\n",
        "  # in the graph has the same feature vector - a torchtensor with \n",
        "  # data [1., 1., 1., 1., 1.]\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note\n",
        "  ## 1. Look up NetworkX `nx.classes.function.set_node_attributes`\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  assign_node_types(G, community_map)\n",
        "  assign_node_labels(G, community_map)\n",
        "  assign_node_features(G)\n",
        "\n",
        "  # Explore node properties for the node with id: 20\n",
        "  node_id = 20\n",
        "  print (f\"Node {node_id} has properties:\", G.nodes(data=True)[node_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mafN0P3EOhSb"
      },
      "source": [
        "### Question 1.2: Assigning Edge Types (2.5 points)\n",
        "\n",
        "Next, we will assign three different `edge_types`: \n",
        "* Edges within club \"Mr. Hi\": `e0`\n",
        "* Edges within club \"Officer\": `e1`\n",
        "* Edges between the two clubs: `e2`\n",
        "\n",
        "**Hint**: Use the `community_map` from before and `nx.classes.function.set_edge_attributes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsbYWEVwSV5n",
        "outputId": "14ac337e-401d-4f45-af22-c2d74fec9fa2"
      },
      "outputs": [],
      "source": [
        "def assign_edge_types(G, community_map):\n",
        "  # TODO: Implement a function that takes in a NetworkX graph\n",
        "  # G and community map assignment (mapping node id --> 0/1 label)\n",
        "  # and adds 'edge_type' as a edge_attribute in G.\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~5 line of code)\n",
        "  ## Note\n",
        "  ## 1. Create an edge assignment dict following rules above\n",
        "  ## 2. Look up NetworkX `nx.classes.function.set_edge_attributes`\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  assign_edge_types(G, community_map)\n",
        "\n",
        "  # Explore edge properties for a sampled edge and check the corresponding\n",
        "  # node types\n",
        "  edge_idx = 15\n",
        "  n1 = 0\n",
        "  n2 = 31\n",
        "  edge = list(G.edges(data=True))[edge_idx]\n",
        "  print (f\"Edge ({edge[0]}, {edge[1]}) has properties:\", edge[2])\n",
        "  print (f\"Node {n1} has properties:\", G.nodes(data=True)[n1])\n",
        "  print (f\"Node {n2} has properties:\", G.nodes(data=True)[n2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBsTdTPVTQ52"
      },
      "source": [
        "## Heterogeneous Graph Visualization\n",
        "\n",
        "Now we can visualize the Heterogeneous Graph we have generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "n2sdufbODHtp",
        "outputId": "537ccd30-1a65-4634-e8a6-d3e1ebb46b0e"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  edge_color = {}\n",
        "  for edge in G.edges():\n",
        "    n1, n2 = edge\n",
        "    edge_color[edge] = community_map[n1] if community_map[n1] == community_map[n2] else 2\n",
        "    if community_map[n1] == community_map[n2] and community_map[n1] == 0:\n",
        "      edge_color[edge] = 'blue'\n",
        "    elif community_map[n1] == community_map[n2] and community_map[n1] == 1:\n",
        "      edge_color[edge] = 'red'\n",
        "    else:\n",
        "      edge_color[edge] = 'green'\n",
        "\n",
        "  G_orig = copy.deepcopy(G)\n",
        "  nx.classes.function.set_edge_attributes(G, edge_color, name='color')\n",
        "  colors = nx.get_edge_attributes(G,'color').values()\n",
        "  labels = nx.get_node_attributes(G, 'node_type')\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=node_color, edge_color=colors, labels=labels, font_color='white')\n",
        "  show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRANkF1jRxLV"
      },
      "source": [
        "You should see that we differentiate edges within each clubs (2 types) and edges between the two clubs (1 type). Different types of nodes and edges are visualized in different colors. The NetworkX object `G` in following code can be transformed into `deepsnap.hetero_graph.HeteroGraph` directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DW8L0hxbxw4"
      },
      "source": [
        "## Transforming to DeepSNAP representation\n",
        "\n",
        "You will now work through transforming the NetworkX object `G` into a `deepsnap.hetero_graph.HeteroGraph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZfHZ_eoVVGd"
      },
      "outputs": [],
      "source": [
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  hete = HeteroGraph(G_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izq4t_O9WxDH"
      },
      "source": [
        "## Question 1.3: How many nodes are of each type (2.5 Points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRNSP6nnW78C",
        "outputId": "4626c0b6-385a-49b1-beb7-bfe5b94983d0"
      },
      "outputs": [],
      "source": [
        "def get_nodes_per_type(hete):\n",
        "  # TODO: Implement a function that takes a DeepSNAP dataset object\n",
        "  # and return the number of nodes per `node_type`.\n",
        "\n",
        "  num_nodes_n0 = 0\n",
        "  num_nodes_n1 = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note\n",
        "  ## 1. Colab autocomplete functionality might be useful.\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return num_nodes_n0, num_nodes_n1\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  num_nodes_n0, num_nodes_n1 = get_nodes_per_type(hete)\n",
        "  print(\"Node type n0 has {} nodes\".format(num_nodes_n0))\n",
        "  print(\"Node type n1 has {} nodes\".format(num_nodes_n1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEsHJp2ZYaE2"
      },
      "source": [
        "## Question 1.4: Message Types - How many edges are of each message type (2.5 Points)\n",
        "\n",
        "When working with heterogenous graphs, we now have heterogenous message types (i.e. different message types for the different `node_type` and `edge_type` combinations). For example, an edge of type `e0` connecting two nodes in club \"Mr. HI\" would have a message type of (`n0`, `e0`, `n0`). In this problem we will analyze how many edges in our graph are of each message type.\n",
        "\n",
        "**Hint**: If you want to learn more about what the different message types are try the call `hete.message_types`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qobKuqbAYvJ7",
        "outputId": "a31af149-9c12-4ff2-b7ed-a664062c263e"
      },
      "outputs": [],
      "source": [
        "def get_num_message_edges(hete):\n",
        "  # TODO: Implement this function that takes a DeepSNAP dataset object\n",
        "  # and return the number of edges for each message type. \n",
        "  # You should return a list of tuples as \n",
        "  # (message_type, num_edge)\n",
        "\n",
        "  message_type_edges = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note\n",
        "  ## 1. Colab autocomplete functionality might be useful.\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return message_type_edges\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  message_type_edges = get_num_message_edges(hete)\n",
        "  for (message_type, num_edges) in message_type_edges:\n",
        "    print(\"Message type {} has {} edges\".format(message_type, num_edges))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMVik1JbJ76"
      },
      "source": [
        "## Question 1.5: Dataset Splitting - How many nodes are in each dataset split? (2.5 Points)\n",
        "\n",
        "DeepSNAP has built in Dataset creation and splitting methods for heterogeneous graphs. Here you will create train, validation, and test datasets for a node prediction task and inspect the resulting subgraphs. Specifically, write a function that computes the number of nodes with a known label in each dataset split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct10Oh4gcqgD",
        "outputId": "f6914ed1-285a-4ffa-a734-ebe8aa0431ea"
      },
      "outputs": [],
      "source": [
        "from deepsnap.dataset import GraphDataset\n",
        "\n",
        "def compute_dataset_split_counts(datasets):\n",
        "  # TODO: Implement a function that takes a dict of datasets in the form\n",
        "  # {'train': dataset_train, 'val': dataset_val, 'test': dataset_test}\n",
        "  # and returns a dict mapping dataset names to the number of labeled\n",
        "  # nodes used for supervision in that respective dataset.  \n",
        "  \n",
        "  data_set_splits = {}\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## (~3 line of code)\n",
        "  ## Note\n",
        "  ## 1. The DeepSNAP `node_label_index` dictionary will be helpful.\n",
        "  ## 2. Remember to count both node_types\n",
        "  ## 3. Remember each dataset only has one graph that we need to access \n",
        "  ##    (i.e. dataset[0])\n",
        "  pass\n",
        "  #########################################\n",
        "\n",
        "  return data_set_splits\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  dataset = GraphDataset([hete], task='node')\n",
        "  # Splitting the dataset\n",
        "  dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.4, 0.3, 0.3])\n",
        "  datasets = {'train': dataset_train, 'val': dataset_val, 'test': dataset_test}\n",
        "\n",
        "  data_set_splits = compute_dataset_split_counts(datasets)\n",
        "  for dataset_name, num_nodes in data_set_splits.items():\n",
        "    print(\"{} dataset has {} nodes\".format(dataset_name, num_nodes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFY2PaDbVKe4"
      },
      "source": [
        "## DeepSNAP Dataset Visualization\n",
        "\n",
        "Now you can visualize the different nodes and edges used in each graph dataset split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iiyEw-agbgV8",
        "outputId": "94fc0f2c-3b2e-4873-d157-55769974381b"
      },
      "outputs": [],
      "source": [
        "from deepsnap.dataset import GraphDataset\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  dataset = GraphDataset([hete], task='node')\n",
        "  # Splitting the dataset\n",
        "  dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.4, 0.3, 0.3])\n",
        "  titles = ['Train', 'Validation', 'Test']\n",
        "\n",
        "  for i, dataset in enumerate([dataset_train, dataset_val, dataset_test]):\n",
        "    n0 = hete._convert_to_graph_index(dataset[0].node_label_index['n0'], 'n0').tolist()\n",
        "    n1 = hete._convert_to_graph_index(dataset[0].node_label_index['n1'], 'n1').tolist()\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.title(titles[i])\n",
        "    nx.draw(G_orig, pos=pos, node_color=\"grey\", edge_color=colors, labels=labels, font_color='white')\n",
        "    nx.draw_networkx_nodes(G_orig.subgraph(n0), pos=pos, node_color=\"blue\")\n",
        "    nx.draw_networkx_nodes(G_orig.subgraph(n1), pos=pos, node_color=\"red\")\n",
        "    show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5LsVSRuI3hU"
      },
      "source": [
        "# 2) Heterogeneous Graph Node Property Prediction\n",
        "\n",
        "Now that we have introduced you to the basics of Heterogeneous graphs, you will use PyTorch Geometric and DeepSNAP to implement a GNN model for heterogeneous graph node property prediction (node classification). You will draw upon your understanding of heterogeneous graphs from lecture and previous work in implementing GNN layers using PyG (introduced in Colab 3).\n",
        "\n",
        "First let's take a look at the general structure of a heterogeneous GNN layer by working through an example:\n",
        "\n",
        "Let's assume we have a graph $G$, which contains two node types $a$ and $b$, and three message types $m_1=(a, r_1, a)$, $m_2=(a, r_2, b)$ and $m_3=(a, r_3, b)$. For notation sake, we view each message as (src, relation, dst), where messages \"flow\" from src to dst node types. \n",
        "\n",
        "When applying message passing in heterogenous graphs, we separately apply message passing over each message type separately. For example, updating node type $b$ relies on two different message types $m_2$ and $m_3$. For the graph $G$, a heterogeneous GNN layer contains three separate Heterogeneous Message Passing layers (`HeteroGNNConv` in this Colab), where each `HeteroGNNConv` layer performs message passing and aggregation with respect to *only one message type*. Since a message type is viewed as (src, relation, dst) and messages \"flow\" from src to dst, each `HeteroGNNConv` layer only computes embeddings for the *dst* nodes of a given message type. For example, the `HeteroGNNConv` layer for message type $m_2$ outputs updated embedding representations *only* for node's with type b. \n",
        "\n",
        "---\n",
        "\n",
        "An overview of the heterogeneous layer you will create is shown below:\n",
        "\n",
        "![test](https://drive.google.com/uc?export=view&id=1mkp4OeRrvC4iNFTXSywrmI6Pfl5J__gA)\n",
        "\n",
        "where we highlight the following notation:\n",
        "\n",
        "- $H_a^{(l)[m_1]}$ is the intermediate matrix of node embeddings for node type $a$, generated by the $l^{th}$ `HeteroGNNConv` layer for message type $m_1$.\n",
        "- $H_a^{(l)}$ is the matrix with current embeddings for nodes of type $a$ after the $l^{th}$ layer of our Heterogeneous GNN model. Note that these embeddings can rely on one or more intermediate `HeteroGNNConv` layer embeddings(i.e. $H_b^{(l)}$ combines $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$).\n",
        "\n",
        "Since each `HeteroGNNConv` is only applied over a single message type, we additionally define a Heterogeneous GNN Wrapper layer (`HeteroGNNWrapperConv`). This wrapper manages and combines the output of each `HeteroGNNConv` layer in order to generate the complete updated node embeddings for each node type in layer $l$ of our model. More specifically, the $l^{th}$ `HeteroGNNWrapperConv` layer takes as input the node embeddings computed for each message type and node type (e.g. $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$) and aggregates across message types with the same $dst$ node type. The resulting output of the $l^{th}$ `HeteroGNNWrapperConv` layer is the updated embedding matrix $H_i^{(l)}$ for each node type i. \n",
        "\n",
        "Continuing on our example above, to compute the node embeddings $H_b^{(l)}$, the wrapper layer aggregates output embeddings from the `HeteroGNNConv` layers associated with message types $m_2$ and $m_3$ (i.e. $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$). \n",
        "\n",
        "---\n",
        "\n",
        "With the `HeteroGNNWrapperConv` module, we can now draw a \"simplified\" heterogeneous layer structure as follows:\n",
        "\n",
        "<br/>\n",
        "<center>\n",
        "<img src=\"http://web.stanford.edu/class/cs224w/images/colab4/hetero_conv_1.png\"/>\n",
        "</center>\n",
        "<br/>\n",
        "\n",
        "---\n",
        "**NOTE**: \n",
        "As reference, it may be helpful to additionally read through PyG's introduction to heterogeneous graph representations and buidling heterogeneous GNN models: https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOTCyuRcJikS"
      },
      "source": [
        "<font color='red'>Looking ahead, we recommend you implement the heterogeneous GNN model in following steps:</font>\n",
        "\n",
        "1. Implement `HeteroGNNConv`.\n",
        "2. Implement **just** `mean` aggregation within `HeteroGNNWrapperConv`.\n",
        "3. Implement `generate_convs`.\n",
        "4. Implement the `HeteroGNN` model and the `train` function.\n",
        "5. Train the model with `mean` aggregation and test your model to make sure your model has reasonable performance.\n",
        "6. Once you are confident in your mean aggregation model, implement `attn` aggregation in `HeteroGNNWrapperConv`.\n",
        "7. Train the model with `attn` aggregation and test your model to make sure your model has reasonable performance.\n",
        "\n",
        "Note: The key point of advice is to work completely through implementing the mean aggregation heterogeneous GNN model before diving into the more difficult attention based model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkFjcktiJJLm"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAm9_OcJJJ-W"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import deepsnap\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from deepsnap.hetero_gnn import forward_op\n",
        "from deepsnap.hetero_graph import HeteroGraph\n",
        "from torch_sparse import SparseTensor, matmul"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n2prITo3JSbo"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "If you are working over Google Colab, you would need to login to your Google account and enter the verification code below. If on the other hand you are working locally, you should comment out the following two related cells downloading the data from Google Drive, as the file is already part of the repository and therefore is locally available!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvQwxJX4JTJX"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # Authenticate and create the PyDrive client\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igoy4F_xJbVn"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  id='1ivlxd6lJMcZ9taS44TMGG72x2V1GeVvk'\n",
        "  downloaded = drive.CreateFile({'id': id})\n",
        "  downloaded.GetContentFile('acm.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBlboS5kJmJL"
      },
      "source": [
        "## Implementing `HeteroGNNConv`\n",
        "\n",
        "Now let's start working on your own implementation of the heterogeneous message passing layer (`HeteroGNNConv`)! Just as in Colab 3, you will implement the layer using PyTorch Geometric. \n",
        "\n",
        "At a high level, the `HeteroGNNConv` layer is equivalent to the homogenous GNN layers you implemented in Colab 3, but now applied to an individual heterogeneous message type. Moreover, our heterogeneous GNN layer draws directly from the **GraphSAGE** message passing model ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)).\n",
        "\n",
        "You will begin by defining the `HeteroGNNConv` layer with respect to message type $m$:\n",
        "\n",
        "\\begin{equation}\n",
        "m =(s, r, d)\n",
        "\\end{equation}\n",
        "\n",
        "where each message type is a tuple containing three elements: $s$ - the source node type, $r$ - the edge (relation) type, and $d$ - the destination node type. \n",
        "\n",
        "The message passing update rule that you will implement is very similar to that of GraphSAGE, except you now need to include the node types and the edge relation type. The update rule for message type $m$ is described below:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)[m]} = W^{(l)[m]} \\cdot \\text{CONCAT} \\Big( W_d^{(l)[m]} \\cdot h_v^{(l-1)}, W_s^{(l)[m]} \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N_{m}(v) \\})\\Big)\n",
        "\\end{equation}\n",
        "\n",
        "where you compute $h_v^{(l)[m]}$, the node embedding representation for node $v$ after `HeteroGNNConv` layer $l$ with respect message type $m$. Further unpacking the formula:\n",
        "- $W_s^{(l)[m]}$ - linear transformation matrix for the messages of neighboring source nodes of type $s$ along message type $m$.\n",
        "- $W_d^{(l)[m]}$ - linear transformation matrix for the message from the node $v$ itself of type $d$.\n",
        "- $W^{(l)[m]}$ - linear transformation matrix for the concatenated messages from neighboring node's and the central node.\n",
        "- $h_u^{(l-1)}$ - the hidden embedding representation for node $u$ after the $(l-1)^{th}$ `HeteroGNNWrapperConv` layer. Note, that this embedding is not associated with a particular message type (see layer diagrams above). \n",
        "- $N_{m}(v)$ - the set of neighbor source nodes $s$ for the node v that we are embedding along message type $m = (s, r, d)$. \n",
        "\n",
        "**NOTE**: We emphasize that each weight matrix is associated with a specific message type $[m]$ and additionally, the weight matrices applied to node messages are differentiated by node type (i.e. $W_s$ and $W_d$).\n",
        "\n",
        "Lastly, for simplicity, we use mean aggregations for $AGG$ where:\n",
        "\n",
        "\\begin{equation}\n",
        "AGG(\\{h_u^{(l-1)}, \\forall u \\in N_{m}(v) \\}) = \\frac{1}{|N_{m}(v)|} \\sum_{u\\in N_{m}(v)} h_u^{(l-1)}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z1b0Mf8Jova"
      },
      "outputs": [],
      "source": [
        "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
        "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
        "        super(HeteroGNNConv, self).__init__(aggr=\"mean\")\n",
        "\n",
        "        self.in_channels_src = in_channels_src\n",
        "        self.in_channels_dst = in_channels_dst\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # To simplify implementation, please initialize both self.lin_dst\n",
        "        # and self.lin_src out_features to out_channels\n",
        "        self.lin_dst = None\n",
        "        self.lin_src = None\n",
        "\n",
        "        self.lin_update = None\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~3 lines of code)\n",
        "        ## Note:\n",
        "        ## 1. Initialize the 3 linear layers.\n",
        "        ## 2. Think through the connection between the mathematical\n",
        "        ##    definition of the update rule and torch linear layers!\n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        node_feature_src,\n",
        "        node_feature_dst,\n",
        "        edge_index,\n",
        "        size=None\n",
        "    ):\n",
        "        ############# Your code here #############\n",
        "        ## (~1 line of code)\n",
        "        ## Note:\n",
        "        ## 1. Unlike Colab 3, we just need to call self.propagate with \n",
        "        ## proper arguments and return its output.\n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~1 line of code)\n",
        "        ## Note:\n",
        "        ## 1. Different from what we implemented in Colab 3, we use message_and_aggregate\n",
        "        ##    to combine the previously seperate message and aggregate functions. \n",
        "        ##    The benefit is that we can avoid materializing x_i and x_j\n",
        "        ##    to make the implementation more efficient.\n",
        "        ## 2. To implement efficiently, refer to PyG documentation for message_and_aggregate\n",
        "        ##    and sparse-matrix multiplication:\n",
        "        ##    https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "        ## 3. Here edge_index is torch_sparse SparseTensor. Although interesting, you\n",
        "        ##    do not need to deeply understand SparseTensor represenations!\n",
        "        ## 4. Conceptually, think through how the message passing and aggregation\n",
        "        ##    expressed mathematically can be expressed through matrix multiplication.\n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def update(self, aggr_out, node_feature_dst):\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~4 lines of code)\n",
        "        ## Note:\n",
        "        ## 1. The update function is called after message_and_aggregate\n",
        "        ## 2. Think through the one-one connection between the mathematical update\n",
        "        ##    rule and the 3 linear layers defined in the constructor. \n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "        return aggr_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKq8ScTiJthn"
      },
      "source": [
        "## Heterogeneous GNN Wrapper Layer\n",
        "\n",
        "After implementing the `HeteroGNNConv` layer for each message type, you need to manage and aggregate the node embedding results (with respect to each message types). Here you will implement two types of message type level aggregation.\n",
        "\n",
        "The first one is simply mean aggregation over message types:\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = \\frac{1}{M}\\sum_{m=1}^{M}h_v^{(l)[m]}\n",
        "\\end{equation}\n",
        "\n",
        "where node $v$ has node type $d$ and we sum over the $M$ message types that have destination node type $d$. From our original example, for a node v of type $b$ you aggregate v's `HeteroGNNConv` embeddings for message types $m_2$ and $m_3$ (i.e. $h_v^{(l)[m_2]}$ and $h_v^{(l)[m_3]}$).\n",
        "\n",
        "The second method you will implement is the semantic level attention introduced in **HAN** ([Wang et al. (2019)](https://arxiv.org/abs/1903.07293)). Instead of directly averaging on the message type aggregation results, you use attention to learn which message type result is more important, then aggregate across all the message types. Below are the equations for semantic level attention:\n",
        "\n",
        "\\begin{equation}\n",
        "e_{m} = \\frac{1}{|V_{d}|} \\sum_{v \\in V_{d}} q_{attn}^{(l)T} \\cdot tanh \\Big( W_{attn}^{(l)} \\cdot h_v^{(l)[m]} + b \\Big)\n",
        "\\end{equation}\n",
        "\n",
        "where $m$ is the message type and $d$ refers to the destination node type for that message ($m = (s, r, d)$). Additionally, $V_{d}$ refers to the set of nodes v with type $d$. Lastly, the unnormalized attention weight $e_m$ is a scaler computed for each message type $m$. \n",
        "\n",
        "Next, you can compute the normalized attention weights and update $h_v^{(l)}$:\n",
        "\n",
        "\\begin{equation}\n",
        "\\alpha_{m} = \\frac{\\exp(e_{m})}{\\sum_{m=1}^M \\exp(e_{m})}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "h_v^{(l)} = \\sum_{m=1}^{M} \\alpha_{m} \\cdot h_v^{(l)[m]}\n",
        "\\end{equation}\n",
        "\n",
        ", where we emphasize that $M$ here is the number of message types associated with the destination node type $d$. \n",
        "\n",
        "**Note**: The implementation of the attention aggregation is tricky and nuanced. We strongly recommend working carefully through the math equations to undersatnd exactly what each notation refers to and how all the pieces fit together. If you can, try to connect the math to our original example, focusing on node type $b$, which depends on two different message types!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_bun02xJwFm"
      },
      "outputs": [],
      "source": [
        "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
        "    def __init__(self, convs, args, aggr=None):\n",
        "        super(HeteroGNNWrapperConv, self).__init__(convs, None)\n",
        "        self.aggr = aggr\n",
        "\n",
        "        # Map the index and message type\n",
        "        self.mapping = {}\n",
        "\n",
        "        # A numpy array that stores the final attention probability\n",
        "        self.alpha = None\n",
        "\n",
        "        self.attn_proj = None\n",
        "\n",
        "        if self.aggr == \"attn\":\n",
        "            ############# Your code here #############\n",
        "            ## (~1 line of code)\n",
        "            ## Note:\n",
        "            ## 1. Initialize self.attn_proj, where self.attn_proj should include\n",
        "            ##    two linear layers. Note, make sure you understand\n",
        "            ##    which part of the equation self.attn_proj captures.\n",
        "            ## 2. You should use nn.Sequential for self.attn_proj\n",
        "            ## 3. nn.Linear and nn.Tanh are useful.\n",
        "            ## 4. You can model a weight vector (rather than matrix) by using:\n",
        "            ##    nn.Linear(some_size, 1, bias=False).\n",
        "            ## 5. The first linear layer should have out_features as args['attn_size']\n",
        "            ## 6. You can assume we only have one \"head\" for the attention.\n",
        "            ## 7. We recommend you to implement the mean aggregation first. After \n",
        "            ##    the mean aggregation works well in the training, then you can \n",
        "            ##    implement this part.\n",
        "            pass\n",
        "            ##########################################\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "        super(HeteroGNNWrapperConv, self).reset_parameters()\n",
        "        if self.aggr == \"attn\":\n",
        "            for layer in self.attn_proj.children():\n",
        "                layer.reset_parameters()\n",
        "    \n",
        "    def forward(self, node_features, edge_indices):\n",
        "        message_type_emb = {}\n",
        "        for message_key, edge_index in edge_indices.items():\n",
        "            src_type, edge_type, dst_type = message_key\n",
        "            node_feature_src = node_features[src_type]\n",
        "            node_feature_dst = node_features[dst_type]\n",
        "            message_type_emb[message_key] = (\n",
        "                self.convs[message_key](\n",
        "                    node_feature_src,\n",
        "                    node_feature_dst,\n",
        "                    edge_index,\n",
        "                )\n",
        "            )\n",
        "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
        "        mapping = {}        \n",
        "        for (src, edge_type, dst), item in message_type_emb.items():\n",
        "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
        "            node_emb[dst].append(item)\n",
        "        self.mapping = mapping\n",
        "        for node_type, embs in node_emb.items():\n",
        "            if len(embs) == 1:\n",
        "                node_emb[node_type] = embs[0]\n",
        "            else:\n",
        "                node_emb[node_type] = self.aggregate(embs)\n",
        "        return node_emb\n",
        "    \n",
        "    def aggregate(self, xs):\n",
        "        # TODO: Implement this function that aggregates all message type results for one node type.\n",
        "        # Here, xs is a list of tensors (embeddings) with respect to message \n",
        "        # type aggregation results.\n",
        "        \n",
        "        # Useful dimensions from xs - particularly for `attn` aggregation\n",
        "        N = xs[0].shape[0] # Number of nodes for the given node type\n",
        "        M = len(xs) # Number of message types for the given node type\n",
        "\n",
        "        if self.aggr == \"mean\":\n",
        "\n",
        "            ############# Your code here #############\n",
        "            ## (~2 lines of code)\n",
        "            ## Note:\n",
        "            ## 1. Explore the function parameter `xs`! \n",
        "            pass\n",
        "            ##########################################\n",
        "\n",
        "        elif self.aggr == \"attn\":\n",
        "            ############# Your code here #############\n",
        "            ## (~10 lines of code)\n",
        "            ## Note:\n",
        "            ## 1. Try to map out how the equations can be translated into code.\n",
        "            ## 2. N and M defined above may be useful at least to understand.\n",
        "            ## 3. Work first to compute the un-normalized attention weights e\n",
        "            ##    for each message type - try to vectorize this!\n",
        "            ## 4. torch.softmax and torch.cat are useful.\n",
        "            ## 5. It might be useful to reshape and concatenate tensors using the  \n",
        "            ##    `view()` function https://pytorch.org/docs/stable/tensor_view.html\n",
        "            ##    and `torch.cat()`https://pytorch.org/docs/stable/generated/torch.cat.html\n",
        "            ## 6. Store the value of attention alpha (as a numpy array) to self.alpha,\n",
        "            ##    which has the shape (len(xs), ) self.alpha will be not be used \n",
        "            ##    to backpropagate etc. in the model. We will use it to see how much \n",
        "            ##    attention the layer pays on different message types.\n",
        "            pass\n",
        "            ##########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn_pnCOKJw-d"
      },
      "source": [
        "## Initialize Heterogeneous GNN Layers\n",
        "\n",
        "Now let's put it all together and initialize the Heterogeneous GNN Layers. Different from the homogeneous graph case, heterogeneous graphs can be a little bit complex.\n",
        "\n",
        "In general, you need to create a dictionary of `HeteroGNNConv` layers where the keys are message types.\n",
        "\n",
        "* To get all message types, `deepsnap.hetero_graph.HeteroGraph.message_types` is useful.\n",
        "* When you initialize the first conv layers, you need to get the feature dimension of each node type. Using `deepsnap.hetero_graph.HeteroGraph.num_node_features(node_type)` will return the node feature dimension of `node_type`. In this function, you will set each `HeteroGNNConv` `out_channels` to be `hidden_size`.\n",
        "* For the remaining conv layers, all node types will have the same embedding dimension `hidden_size` and we still set `HeteroGNNConv` `out_channels` to be `hidden_size` for simplicity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSBImHClJzf4"
      },
      "outputs": [],
      "source": [
        "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
        "    # TODO: Implement this function that returns a dictionary of `HeteroGNNConv` \n",
        "    # layers where the keys are message types. `hetero_graph` is deepsnap `HeteroGraph`\n",
        "    # object and the `conv` is the `HeteroGNNConv`.\n",
        "\n",
        "    convs = {}\n",
        "\n",
        "    ############# Your code here #############\n",
        "    ## (~9 lines of code)\n",
        "    ## Note:\n",
        "    ## 1. See the hints above!\n",
        "    ## 2. conv is of type `HeteroGNNConv`\n",
        "    pass\n",
        "    ##########################################\n",
        "    \n",
        "    return convs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U39dX8EpJ3FG"
      },
      "source": [
        "## HeteroGNN\n",
        "\n",
        "Now you will make a simple HeteroGNN model which contains only two `HeteroGNNWrapperConv` layers.\n",
        "\n",
        "For the forward function in `HeteroGNN`, the model is going to be run as following:\n",
        "\n",
        "$\\text{self.convs1} \\rightarrow \\text{self.bns1} \\rightarrow \\text{self.relus1} \\rightarrow \\text{self.convs2} \\rightarrow \\text{self.bns2} \\rightarrow \\text{self.relus2} \\rightarrow \\text{self.post_mps}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rplknA8aJ6J5"
      },
      "outputs": [],
      "source": [
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, hetero_graph, args, aggr=\"mean\"):\n",
        "        super(HeteroGNN, self).__init__()\n",
        "\n",
        "        self.aggr = aggr\n",
        "        self.hidden_size = args['hidden_size']\n",
        "\n",
        "        self.convs1 = None\n",
        "        self.convs2 = None\n",
        "\n",
        "        self.bns1 = nn.ModuleDict()\n",
        "        self.bns2 = nn.ModuleDict()\n",
        "        self.relus1 = nn.ModuleDict()\n",
        "        self.relus2 = nn.ModuleDict()\n",
        "        self.post_mps = nn.ModuleDict()\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~10 lines of code)\n",
        "        ## Note:\n",
        "        ## 1. For self.convs1 and self.convs2, call generate_convs at first and then\n",
        "        ##    pass the returned dictionary of `HeteroGNNConv` to `HeteroGNNWrapperConv`.\n",
        "        ## 2. For self.bns, self.relus and self.post_mps, the keys are node_types.\n",
        "        ##    `deepsnap.hetero_graph.HeteroGraph.node_types` will be helpful.\n",
        "        ## 3. Initialize all batchnorms to torch.nn.BatchNorm1d(hidden_size, eps=1).\n",
        "        ## 4. Initialize all relus to nn.LeakyReLU().\n",
        "        ## 5. For self.post_mps, each value in the ModuleDict is a linear layer \n",
        "        ##    where the `out_features` is the number of classes for that node type.\n",
        "        ##    `deepsnap.hetero_graph.HeteroGraph.num_node_labels(node_type)` will be\n",
        "        ##    useful.\n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "    def forward(self, node_feature, edge_index):\n",
        "        # TODO: Implement the forward function. Notice that `node_feature` is \n",
        "        # a dictionary of tensors where keys are node types and values are \n",
        "        # corresponding feature tensors. The `edge_index` is a dictionary of \n",
        "        # tensors where keys are message types and values are corresponding\n",
        "        # edge index tensors (with respect to each message type).\n",
        "\n",
        "        x = node_feature\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~7 lines of code)\n",
        "        ## Note:\n",
        "        ## 1. `deepsnap.hetero_gnn.forward_op` can be helpful for\n",
        "        ##    the bn, relu, and post_mp ops.\n",
        "        pass\n",
        "        ##########################################\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def loss(self, preds, y, indices):\n",
        "        \n",
        "        loss = 0\n",
        "        loss_func = F.cross_entropy\n",
        "\n",
        "        ############# Your code here #############\n",
        "        ## (~3 lines of code)\n",
        "        ## Note:\n",
        "        ## 1. For each node type in preds, accumulate computed loss to `loss`\n",
        "        ## 2. Loss need to be computed with respect to the given index\n",
        "        ## 3. preds is a dictionary of model predictions keyed by node_type.\n",
        "        ## 4. indeces is a dictionary of labeled supervision nodes keyed\n",
        "        ##    by node_type\n",
        "        pass\n",
        "        ##########################################\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9e7q_hUJ8zB"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Here we provide you with the functions to train and test. You only need to implement one line of code here.\n",
        "\n",
        "**Please do not modify other parts in `train` and `test` for grading purposes.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI5Hl_5TJ_YL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def train(model, optimizer, hetero_graph, train_idx):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(hetero_graph.node_feature, hetero_graph.edge_index)\n",
        "\n",
        "    loss = None\n",
        "\n",
        "    ############# Your code here #############\n",
        "    ## Note:\n",
        "    ## 1. Compute the loss here\n",
        "    ## 2. `deepsnap.hetero_graph.HeteroGraph.node_label` is useful\n",
        "    pass\n",
        "    ##########################################\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, graph, indices, best_model=None, best_val=0, save_preds=False, agg_type=None):\n",
        "    model.eval()\n",
        "    accs = []\n",
        "    for i, index in enumerate(indices):\n",
        "        preds = model(graph.node_feature, graph.edge_index)\n",
        "        num_node_types = 0\n",
        "        micro = 0\n",
        "        macro = 0\n",
        "        for node_type in preds:\n",
        "            idx = index[node_type]\n",
        "            pred = preds[node_type][idx]\n",
        "            pred = pred.max(1)[1]\n",
        "            label_np = graph.node_label[node_type][idx].cpu().numpy()\n",
        "            pred_np = pred.cpu().numpy()\n",
        "            micro = f1_score(label_np, pred_np, average='micro')\n",
        "            macro = f1_score(label_np, pred_np, average='macro')\n",
        "            num_node_types += 1\n",
        "                  \n",
        "        # Averaging f1 score might not make sense, but in our example we only\n",
        "        # have one node type\n",
        "        micro /= num_node_types\n",
        "        macro /= num_node_types\n",
        "        accs.append((micro, macro))\n",
        "\n",
        "        # Only save the test set predictions and labels!\n",
        "        if save_preds and i == 2:\n",
        "          print (\"Saving Heterogeneous Node Prediction Model Predictions with Agg:\", agg_type)\n",
        "          print()\n",
        "\n",
        "          data = {}\n",
        "          data['pred'] = pred_np\n",
        "          data['label'] = label_np\n",
        "\n",
        "          df = pd.DataFrame(data=data)\n",
        "          # Save locally as csv\n",
        "          df.to_csv('ACM-Node-' + agg_type + 'Agg.csv', sep=',', index=False)\n",
        "\n",
        "    if accs[1][0] > best_val:\n",
        "        best_val = accs[1][0]\n",
        "        best_model = copy.deepcopy(model)\n",
        "    return accs, best_model, best_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpNz9B5AKBUU"
      },
      "outputs": [],
      "source": [
        "# Please do not change the following parameters\n",
        "args = {\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'hidden_size': 64,\n",
        "    'epochs': 100,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr': 0.003,\n",
        "    'attn_size': 32,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7POWyQqmAtH"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=224):\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRHbWD4hKED8"
      },
      "source": [
        "## Dataset and Preprocessing\n",
        "\n",
        "Before testing out your model, you need to load the data and create a tensor backend (without a NetworkX graph) `deepsnap.hetero_graph.HeteroGraph` object.\n",
        "\n",
        "You will use the `ACM(3025)` dataset to test your model on a node property prediction task, which is proposed in **HAN** ([Wang et al. (2019)](https://arxiv.org/abs/1903.07293)) and extracted from [DGL](https://www.dgl.ai/)'s [ACM.mat](https://data.dgl.ai/dataset/ACM.mat).\n",
        "\n",
        "The original ACM dataset has three node types and two edge (relation) types. For simplicity, we simplify the heterogeneous graph to one node type and two edge types (shown below). This means that in you heterogeneous graph, we have one node type (paper) and two message types (paper, author, paper) and (paper, subject, paper).\n",
        "\n",
        "<br/>\n",
        "<center>\n",
        "<img src=\"http://web.stanford.edu/class/cs224w/images/colab4/cs224w-acm.png\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJy03_IsKGh6",
        "outputId": "e14b9975-3cb9-4561-ec85-3978f70026c8"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  print(\"Device: {}\".format(args['device']))\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  # Load the data\n",
        "  data = torch.load(\"acm.pkl\")\n",
        "\n",
        "  # Message types\n",
        "  message_type_1 = (\"paper\", \"author\", \"paper\")\n",
        "  message_type_2 = (\"paper\", \"subject\", \"paper\")\n",
        "\n",
        "  # Dictionary of edge indices\n",
        "  edge_index = {}\n",
        "  edge_index[message_type_1] = data['pap']\n",
        "  edge_index[message_type_2] = data['psp']\n",
        "\n",
        "  # Dictionary of node features\n",
        "  node_feature = {}\n",
        "  node_feature[\"paper\"] = data['feature']\n",
        "\n",
        "  # Dictionary of node labels\n",
        "  node_label = {}\n",
        "  node_label[\"paper\"] = data['label']\n",
        "\n",
        "  # Load the train, validation and test indices\n",
        "  train_idx = {\"paper\": data['train_idx'].to(args['device'])}\n",
        "  val_idx = {\"paper\": data['val_idx'].to(args['device'])}\n",
        "  test_idx = {\"paper\": data['test_idx'].to(args['device'])}\n",
        "\n",
        "  # Construct a deepsnap tensor backend HeteroGraph\n",
        "  hetero_graph = HeteroGraph(\n",
        "      node_feature=node_feature,\n",
        "      node_label=node_label,\n",
        "      edge_index=edge_index,\n",
        "      directed=True\n",
        "  )\n",
        "\n",
        "  print(f\"ACM heterogeneous graph: {hetero_graph.num_nodes()} nodes, {hetero_graph.num_edges()} edges\")\n",
        "\n",
        "  # Node feature and node label to device\n",
        "  for key in hetero_graph.node_feature:\n",
        "      hetero_graph.node_feature[key] = hetero_graph.node_feature[key].to(args['device'])\n",
        "  for key in hetero_graph.node_label:\n",
        "      hetero_graph.node_label[key] = hetero_graph.node_label[key].to(args['device'])\n",
        "\n",
        "  # Edge_index to sparse tensor and to device\n",
        "  for key in hetero_graph.edge_index:\n",
        "      edge_index = hetero_graph.edge_index[key]\n",
        "      adj = SparseTensor(row=edge_index[0], col=edge_index[1], sparse_sizes=(hetero_graph.num_nodes('paper'), hetero_graph.num_nodes('paper')))\n",
        "      hetero_graph.edge_index[key] = adj.t().to(args['device'])\n",
        "  print(hetero_graph.edge_index[message_type_1])\n",
        "  print(hetero_graph.edge_index[message_type_2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrmU5-QQKJv6"
      },
      "source": [
        "## Start Training!\n",
        "\n",
        "Now let's start training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0HplV9hKMkc"
      },
      "source": [
        "## Training the Mean Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgwfyzLbKOUw",
        "outputId": "3d99a154-0e4c-401a-ddcc-f908b6d93183"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  best_model = None\n",
        "  best_val = 0\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  model = HeteroGNN(hetero_graph, args, aggr=\"mean\").to(args['device'])\n",
        "  \n",
        "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
        "  # try:\n",
        "  #   model = torch_geometric.compile(model)\n",
        "  #   print(f\"HeteroGNN Model compiled\")\n",
        "  # except Exception as err:\n",
        "  #   print(f\"Model compile not supported: {err}\")\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      loss = train(model, optimizer, hetero_graph, train_idx)\n",
        "      accs, best_model, best_val = test(model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_val)\n",
        "      print(\n",
        "          f\"Epoch {epoch + 1}: loss {round(loss, 5)}, \"\n",
        "          f\"train micro {round(accs[0][0] * 100, 2)}%, train macro {round(accs[0][1] * 100, 2)}%, \"\n",
        "          f\"valid micro {round(accs[1][0] * 100, 2)}%, valid macro {round(accs[1][1] * 100, 2)}%, \"\n",
        "          f\"test micro {round(accs[2][0] * 100, 2)}%, test macro {round(accs[2][1] * 100, 2)}%\"\n",
        "      )\n",
        "  best_accs, _, _ = test(best_model, hetero_graph, [train_idx, val_idx, test_idx], save_preds=True, agg_type=\"Mean\")\n",
        "  print(\n",
        "      f\"Best model: \"\n",
        "      f\"train micro {round(best_accs[0][0] * 100, 2)}%, train macro {round(best_accs[0][1] * 100, 2)}%, \"\n",
        "      f\"valid micro {round(best_accs[1][0] * 100, 2)}%, valid macro {round(best_accs[1][1] * 100, 2)}%, \"\n",
        "      f\"test micro {round(best_accs[2][0] * 100, 2)}%, test macro {round(best_accs[2][1] * 100, 2)}%\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtkKBI_nKS1T"
      },
      "source": [
        "## Question 2.1: What is your maximum test set **micro** F1 score for the best_model when using mean aggregation? (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIvw51jMKTvn"
      },
      "source": [
        "## Question 2.2: What is your maximum test set **macro** F1 score for the best_model when using the mean aggregation? (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBiYvwcuKd0z"
      },
      "source": [
        "## Training the Attention Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6na5zyQKfvi",
        "outputId": "f83a1dbf-9490-42d0-fb61-75c88f5dbbe0"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  best_model = None\n",
        "  best_val = 0\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  output_size = hetero_graph.num_node_labels('paper')\n",
        "  model = HeteroGNN(hetero_graph, args, aggr=\"attn\").to(args['device'])\n",
        "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
        "  # try:\n",
        "  #   model = torch_geometric.compile(model)\n",
        "  #   print(f\"HeteroGNN Model compiled\")\n",
        "  # except Exception as err:\n",
        "  #   print(f\"Model compile not supported: {err}\")\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
        "\n",
        "  for epoch in range(args['epochs']):\n",
        "      loss = train(model, optimizer, hetero_graph, train_idx)\n",
        "      accs, best_model, best_val = test(model, hetero_graph, [train_idx, val_idx, test_idx], best_model, best_val)\n",
        "      print(\n",
        "          f\"Epoch {epoch + 1}: loss {round(loss, 5)}, \"\n",
        "          f\"train micro {round(accs[0][0] * 100, 2)}%, train macro {round(accs[0][1] * 100, 2)}%, \"\n",
        "          f\"valid micro {round(accs[1][0] * 100, 2)}%, valid macro {round(accs[1][1] * 100, 2)}%, \"\n",
        "          f\"test micro {round(accs[2][0] * 100, 2)}%, test macro {round(accs[2][1] * 100, 2)}%\"\n",
        "      )\n",
        "  best_accs, _, _ = test(best_model, hetero_graph, [train_idx, val_idx, test_idx], save_preds=True, agg_type=\"Attention\")\n",
        "  print(\n",
        "      f\"Best model: \"\n",
        "      f\"train micro {round(best_accs[0][0] * 100, 2)}%, train macro {round(best_accs[0][1] * 100, 2)}%, \"\n",
        "      f\"valid micro {round(best_accs[1][0] * 100, 2)}%, valid macro {round(best_accs[1][1] * 100, 2)}%, \"\n",
        "      f\"test micro {round(best_accs[2][0] * 100, 2)}%, test macro {round(best_accs[2][1] * 100, 2)}%\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtAhFLQQKgbl"
      },
      "source": [
        "## Question 2.3: What is your maximum test set **micro** F1 score for the best_model when using the attention aggregation? (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cnsMGbsqJG_"
      },
      "source": [
        "## Question 2.4: What is your maximum test set **macro** F1 score for the best_model when using the attention aggregation? (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQgx5y4UqMHH"
      },
      "source": [
        "## Attention for each Message Type\n",
        "\n",
        "Through message type level attention, you can learn which message type is more important to which layer.\n",
        "\n",
        "Here you can see how each layer pays different attention to each message type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvK58gijqN_C",
        "outputId": "2a1af73d-8dbf-4043-ae89-ef8771cb1dce"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  if model.convs1.alpha is not None and model.convs2.alpha is not None:\n",
        "      for idx, message_type in model.convs1.mapping.items():\n",
        "          print(f\"Layer 1 has attention {model.convs1.alpha[idx]} on message type {message_type}\")\n",
        "      for idx, message_type in model.convs2.mapping.items():\n",
        "          print(f\"Layer 2 has attention {model.convs2.alpha[idx]} on message type {message_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxkYLgxAOxz7"
      },
      "source": [
        "# 3) Neighbor Sampling\n",
        "\n",
        "In this final part of the Colab, we shift gears slightly and give a preview into the work for Colab5. Here we introduce an advanced topic in GNNs, where you will work with PyTorch Geometric's `NeighborLoader` to scale up training and testing of GNN's on the OGB `arxiv` dataset. Neighbor Sampling, originally proposed in **GraphSAGE** ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)), is a representative method to scale up GNNs. As we learned in lecture, rather than loading the entire graph into memory for each training loop, you can instead sample a mini-batch of the nodes you want to embed and **only** load the K-hop graph neighborhoods needed to embed these nodes. In this way you take advantage of the fact that the embedding of a node u only depends on its K-hop neighborhood. To further reduce the memory footprint and computational cost, you can choose to sample only a subset of a node's neighborhood during message passing and aggregation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kho6SHUVO1ny"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1WJLGKsOx_k",
        "outputId": "0358729d-d8ae-4bcf-cbb5-bc948dc8ddd1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "# Install OGB\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install -q ogb\n",
        "\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqZWqRbO7km"
      },
      "source": [
        "## PyTorch Geometric Neighbor Loader\n",
        "\n",
        "PyTorch Geometric has implemented Neighbor Samplinging through the [NeighborLoader](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader) class. \n",
        "Neighbor sampling is based on building a node\u2019s computation graph without storing irrelevant information for that given node, thus, making it more efficient. Each node produces a single computation graph, where for each node in a k-hop neighborhood, at most, $H_k$ neighbors are randomly sampled. Each node's  computation graph will therefore involve $\\prod^K_{k=1} H_k$ leaf nodes for a K-layer GNN. \n",
        "\n",
        "The successive layers of each node's computation graph can be conceptualized as bi-partite graphs, where each bi-partite graph represents the information flow in one layer of message passing (shown in figure below). Let us look at how one message passing layer is represented through a bi-partite graph. For layer 3, the blue (or black) dots are the source nodes needed to compute message passing (in layer 3 of our GNN) to produce updated embeddings for the target nodes (shown in red). In the bi-partite represention, information flows from left to right, where we highlight that the left hand side of the graph specifically includes the target nodes to allow for skip-connections and added self-loops. Additionally, we stress that moving from one layer to the next, the bi-partite graphs are explicitly constructed so the target nodes for layer $k-1$ are the needed source nodes for layer $k$, where the output of the final layer is exactly the embeddings of the nodes in our minibatch.\n",
        "\n",
        "Note, when constructing mini-batches, individual node computation graphs are combined to create this bi-partite structure. If you'd like to learn more about information on neighborhood sampling, this\n",
        "**[blog](https://towardsdatascience.com/sampling-large-graphs-in-pytorch-geometric-97a6119c41f9)** provides an excellent description.\n",
        "\n",
        "![img]( https://drive.google.com/uc?export=view&id=1QqcrEsN-HpSHgwHiOD4Dh6yIawZh0Pgj)\n",
        "\n",
        "\n",
        "**PyG Docs**\n",
        "\n",
        "The neighbor sampler from the \u201cInductive Representation Learning on Large Graphs\u201d paper, which allows for mini-batch training of GNNs on large-scale graphs where full-batch training is not feasible.\n",
        "\n",
        "Given a GNN with  layers and a specific mini-batch of nodes `node_idx` for which we want to compute embeddings, this module iteratively samples neighbors and constructs bipartite graphs that simulate the actual computation flow of GNNs.\n",
        "\n",
        "More specifically, sizes denotes how much neighbors we want to sample for each node in each layer. This module then takes in these sizes and iteratively samples sizes[l] for each node involved in layer `l`. In the next layer, sampling is repeated for the union of nodes that were already encountered. The actual computation graphs are then returned in reverse-mode, meaning that we pass messages from a larger set of nodes to a smaller one, until we reach the nodes for which we originally wanted to compute embeddings.\n",
        "\n",
        "Hence, an item returned by NeighborLoader holds the current batch_size, the IDs n_id of all nodes involved in the computation, and a list of bipartite graph objects via the tuple (edge_index, e_id, size), where edge_index represents the bipartite edges between source and target nodes, e_id denotes the IDs of original edges in the full graph, and size holds the shape of the bipartite graph. For each bipartite graph, target nodes are also included at the beginning of the list of source nodes so that one can easily apply skip-connections or add self-loops.\n",
        "\n",
        "\n",
        "If you are interested in memory-efficient aggregations, please refer to PyG's [Memory-Efficient Aggregations](https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html).  Following is an example that uses the Neighbor Sampling method on training the OGB `arxiv` dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWlyStlRO6_u",
        "outputId": "8fdca8df-4d91-4f34-a898-f7adf9466385"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  dataset_name = 'ogbn-arxiv'\n",
        "  dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "                                  transform=T.ToSparseTensor())\n",
        "  data = dataset[0]\n",
        "  data.adj_t = data.adj_t.to_symmetric()\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  print('Device: {}'.format(device))\n",
        "\n",
        "  # Already send node features/sparse adjacency matrix/labels to GPU for faster access during sampling\n",
        "  data = data.to(device, 'x', 'adj_t', 'y')\n",
        "  split_idx = dataset.get_idx_split()\n",
        "  train_idx = split_idx['train']\n",
        "\n",
        "  sampled_subgraph_batch_loader = None\n",
        "  full_subgraph_loader = None\n",
        "  \n",
        "  ############# Your code here ############\n",
        "  ## (~2 line of code)\n",
        "  ## Note:\n",
        "  ## 1. Construct the NeighborLoader `sampled_subgraph_batch_loader`. \n",
        "  ##    Use a batch size of 4096, turn shuffle on, and only \n",
        "  ##    use train_idx nodes to create mini-batches. During sampling,\n",
        "  ##    sample up to 10 neighbors in layer one and 5 neighbors in layer 2.\n",
        "  ## 2. Construct the NeighborLoader `full_subgraph_loader`. \n",
        "  ##    Use a batch size of 4096 and turn shuffle off. Sample all neighbors\n",
        "  ##    for both layers and consider all nodes for sampling mini-batches!\n",
        "  ##    We use this loader for the inference / test phase of our model. \n",
        "  ## 3. Look at the NeighborLoader documentation to figure out which \n",
        "  ##    parameters you need to set:\n",
        "  ##    https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader\n",
        "  pass\n",
        "  #################################################################################\n",
        "\n",
        "  evaluator = Evaluator(name='ogbn-arxiv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjdkIcFpRYyl"
      },
      "source": [
        "## GNN Model\n",
        "\n",
        "After creating your `NeighborLoader`, you also need to modify your model to support the mini-batch training.\n",
        "\n",
        "The `inference` function will take the data loader `all_loader` from which the following elements are relevant:\n",
        "* `x`: The node features.\n",
        "* `adj_t`: The adjacency matrix stored as a sparse tensor.\n",
        "* `batch_size`: The size of the batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRBJS_5qRWbu"
      },
      "outputs": [],
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "\n",
        "        self.convs.append(SAGEConv(input_dim, hidden_dim))\n",
        "        self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "\n",
        "        for i in range(num_layers - 2):\n",
        "            self.convs.append(\n",
        "                SAGEConv(hidden_dim, hidden_dim))\n",
        "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
        "        self.convs.append(SAGEConv(hidden_dim, output_dim))\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        \n",
        "        ############# Your code here ############\n",
        "        ## (~6 line of code)\n",
        "        ## Note:\n",
        "        ## 1. Our GNN model is of the form:\n",
        "        ##      conv -> bn -> relu -> dropout -> ... -> conv\n",
        "        pass\n",
        "        #####################################\n",
        "            \n",
        "        return self.softmax(x)\n",
        "    \n",
        "    def inference(self, all_loader):\n",
        "        # This function will be called in test\n",
        "        \n",
        "        xs = []\n",
        "        ############# Your code here ############\n",
        "        ## (~5 line of code)\n",
        "        ## Note:\n",
        "        ## 1. Very similar idea to the forward function!\n",
        "        ## 2. Looping through all_loader to apply the full model to each\n",
        "        ##    batch of nodes, where all_loader contains the following relevant keys/properties:\n",
        "        ##      - batch_size\n",
        "        ##      - x: node features\n",
        "        ##      - adj_t: adjacency matrix stored as a sparse tensor.\n",
        "        ## 3. Remember to move the `x` and `adj_t` for each batch to\n",
        "        ##    the GPU `device`.\n",
        "        ## 4. Pass the batch node features and adjacency matrix to the model.\n",
        "        ## 5. Since we are doing mini-batches of nodes, we now need\n",
        "        ##    to retrieve just the predictions for the current batch, \n",
        "        ##    given by the first batch_size elements and append \n",
        "        ##    them to compute all the predictions!\n",
        "        pass\n",
        "        #####################################\n",
        "        \n",
        "        # Concatenate all predictions into one tensor.\n",
        "        # We simulate the update process at the end of message\n",
        "        # passing. Because of this we only have to sample 1-hop neighborhoods\n",
        "        # for our full_subgraph_loader!\n",
        "        x_all = torch.cat(xs, dim=0)\n",
        "\n",
        "        return x_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cfm7K3wRqqY"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "Now we provide the training and testing functions for you.\n",
        "\n",
        "In both training and testing, we need to sample batches from the dataloader.\n",
        "\n",
        "Each batch in the `NeighborLoader` dataloader holds multiple elements, out of which the following are relevant:\n",
        "* `batch_size`: The batch size specified in the dataloader.\n",
        "* `x`: Node features.\n",
        "* `adj_t`: Adjacency matrix stored as a sparse Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JN0-_QCRn8N"
      },
      "outputs": [],
      "source": [
        "def train(model, data, train_loader, train_idx, optimizer, loss_fn, mode=\"batch\"):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    if mode == \"batch\":\n",
        "\n",
        "        for batched_data in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Index on the node features\n",
        "            batch_size = batched_data.batch_size\n",
        "            out = model(batched_data.x, batched_data.adj_t)[:batch_size]\n",
        "            train_label = batched_data.y[:batch_size].squeeze(-1)\n",
        "            loss = loss_fn(out, train_label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "    else:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.adj_t)[train_idx]\n",
        "        train_label = data.y.squeeze(1)[train_idx]\n",
        "        loss = loss_fn(out, train_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss = loss.item()\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data, all_loader, split_idx, evaluator, mode=\"batch\", save_model_results=False):\n",
        "    model.eval()\n",
        "\n",
        "    if mode == \"batch\":\n",
        "        out = model.inference(all_loader)\n",
        "    else:\n",
        "        out = model(data.x, data.adj_t)\n",
        "\n",
        "    y_true = data.y.cpu()\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': y_true[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    if save_model_results:\n",
        "      print (\"Saving Model Predictions\")\n",
        "\n",
        "      data = {}\n",
        "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "      df = pd.DataFrame(data=data)\n",
        "      # Save locally as csv\n",
        "      df.to_csv('ogbn-arxiv_' + mode + '.csv', sep=',', index=False)\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiehZ8OiR2q9"
      },
      "source": [
        "## Mini-batch Training\n",
        "\n",
        "Test your model using mini-batch training, based on our NeighborLoader!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFaI2eCARy0v",
        "outputId": "1d0165cb-d805-4f01-f74e-16be58a19690"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  args = {\n",
        "      'device': device,\n",
        "      'num_layers': 2,\n",
        "      'hidden_dim': 128,\n",
        "      'dropout': 0.5,\n",
        "      'lr': 0.01,\n",
        "      'epochs': 100,\n",
        "  }\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  batch_model = SAGE(data.num_features, args['hidden_dim'],\n",
        "              dataset.num_classes, args['num_layers'],\n",
        "              args['dropout']).to(device)\n",
        "  # Disable compile as this does not seem to work yet in PyTorch 2.0.1/PyG 2.3.1\n",
        "  # try:\n",
        "  #   batch_model = torch_geometric.compile(batch_model)\n",
        "  #   print(f\"SAGE Model compiled\")\n",
        "  # except Exception as err:\n",
        "  #   print(f\"Model compile not supported: {err}\")\n",
        "    \n",
        "  batch_model.reset_parameters()\n",
        "\n",
        "  optimizer = torch.optim.Adam(batch_model.parameters(), lr=args['lr'])\n",
        "  loss_fn = F.nll_loss\n",
        "\n",
        "  best_batch_model = None\n",
        "  best_valid_acc = 0\n",
        "\n",
        "  batch_results = []\n",
        "\n",
        "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "      loss = train(batch_model, data, sampled_subgraph_batch_loader, train_idx, optimizer, loss_fn, mode=\"batch\")\n",
        "      result = test(batch_model, data, full_subgraph_loader, split_idx, evaluator, mode=\"batch\")\n",
        "      batch_results.append(result)\n",
        "      train_acc, valid_acc, test_acc = result\n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          best_batch_model = copy.deepcopy(batch_model)\n",
        "      print(f'Epoch: {epoch:02d}, '\n",
        "            f'Loss: {loss:.4f}, '\n",
        "            f'Train: {100 * train_acc:.2f}%, '\n",
        "            f'Valid: {100 * valid_acc:.2f}% '\n",
        "            f'Test: {100 * test_acc:.2f}%')\n",
        "  best_result = test(best_batch_model, data, full_subgraph_loader, split_idx, evaluator, mode=\"batch\", save_model_results=True)\n",
        "  train_acc, valid_acc, test_acc = best_result\n",
        "  print(f'Best model: '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% '\n",
        "        f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwcRKcAh16RV"
      },
      "source": [
        "## **Question 3:** What is the maximum accuracy obtained on the test set using mini-batch training? (15 points)\n",
        "\n",
        "Running the cell above will show the results of your best model and save your best model's predictions to a file named ogbn-arxiv_batch.csv'.\n",
        "\n",
        "As you have seen before you can view this file by clicking on the Folder icon on the left side pannel. When you sumbit your assignment, you will have to download this file and attatch it to your submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OyqW-1pSMLW"
      },
      "source": [
        "## Full-batch Training\n",
        "\n",
        "Now for reference, compare training over all the nodes using full-batch mode (i.e. as we have done in the previous Colabs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU5eAviTSFMO",
        "outputId": "f533d2c2-e744-4cf9-dca9-9c0a6e34d493"
      },
      "outputs": [],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:  \n",
        "  # Use the same parameters for a full-batch training\n",
        "  args = {\n",
        "      'device': device,\n",
        "      'num_layers': 2,\n",
        "      'hidden_dim': 128,\n",
        "      'dropout': 0.5,\n",
        "      'lr': 0.01,\n",
        "      'epochs': 100,\n",
        "  }\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  all_model = SAGE(data.num_features, args['hidden_dim'],\n",
        "              dataset.num_classes, args['num_layers'],\n",
        "              args['dropout']).to(device)\n",
        "  all_model.reset_parameters()\n",
        "\n",
        "  optimizer = torch.optim.Adam(all_model.parameters(), lr=args['lr'])\n",
        "  loss_fn = F.nll_loss\n",
        "\n",
        "  best_all_model = None\n",
        "  best_valid_acc = 0\n",
        "\n",
        "  all_results = []\n",
        "\n",
        "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "      # NOTE: For the full batch model, the NeighborLoader loader is not used!\n",
        "      loss = train(all_model, data, sampled_subgraph_batch_loader, train_idx, optimizer, loss_fn, mode=\"all\")\n",
        "      result = test(all_model, data, full_subgraph_loader, split_idx, evaluator, mode=\"all\")\n",
        "      all_results.append(result)\n",
        "      train_acc, valid_acc, test_acc = result\n",
        "      if valid_acc > best_valid_acc:\n",
        "          best_valid_acc = valid_acc\n",
        "          best_all_model = copy.deepcopy(all_model)\n",
        "      print(f'Epoch: {epoch:02d}, '\n",
        "            f'Loss: {loss:.4f}, '\n",
        "            f'Train: {100 * train_acc:.2f}%, '\n",
        "            f'Valid: {100 * valid_acc:.2f}% '\n",
        "            f'Test: {100 * test_acc:.2f}%')\n",
        "  best_result = test(best_all_model, data, full_subgraph_loader, split_idx, evaluator, mode=\"all\")\n",
        "  train_acc, valid_acc, test_acc = best_result\n",
        "  print(f'Best model: '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% '\n",
        "        f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrECcOQQSZo1"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "sh_qvSG1SV63",
        "outputId": "d185fd06-2de5-4267-d218-04ffd6a2e8fc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  batch_results = np.array(batch_results)\n",
        "  all_results = np.array(all_results)\n",
        "\n",
        "  x = np.arange(1, 101)\n",
        "\n",
        "  plt.figure(figsize=(9, 7))\n",
        "\n",
        "  plt.plot(x, batch_results[:, 1], label=\"Batch Validation\")\n",
        "  plt.plot(x, batch_results[:, 2], label=\"Batch Test\")\n",
        "  plt.plot(x, all_results[:, 1], label=\"All Validation\")\n",
        "  plt.plot(x, all_results[:, 2], label=\"All Test\")\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JXsMTBgeOI"
      },
      "source": [
        "# Submission\n",
        "\n",
        "You will need to submit three files on Gradescope to complete this notebook. \n",
        "\n",
        "1.   Your completed *XCS224W_Colab4.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. \n",
        "2.  *ACM-Node-MeanAgg.csv* \n",
        "3.  *ACM-Node-AttentionAgg.csv*\n",
        "4.  *ogbn-arxiv_batch.csv* \n",
        "\n",
        "Download the csv files by selecting the *Folder* icon on the left panel. \n",
        "\n",
        "To submit your work, zip the files downloaded in steps 1-3 above and submit to gradescope. **NOTE:** DO NOT rename any of the downloaded files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_vcsDcYVaGI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}